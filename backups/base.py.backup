"""
Enhanced Base Downloader Module - BULLETPROOF IMPLEMENTATION

This module provides the enhanced base downloader class that works seamlessly
with the new bulletproof configuration system. It includes comprehensive error
handling, multiple configuration access patterns, and robust fallback mechanisms.

Key Features:
- Seamless integration with bulletproof configuration system
- Multiple ways to access configuration settings
- Comprehensive error handling that never crashes
- Intelligent fallback mechanisms for all settings
- Enhanced logging and debugging support
- Robust download statistics and progress tracking

The Enhanced Base Downloader ensures:
- Configuration access never fails
- All settings have safe defaults
- Comprehensive validation of download parameters
- Robust error handling and recovery
- Detailed logging for troubleshooting
- Performance optimization with smart defaults

Usage:
    # Create a custom downloader
    class MyDownloader(EnhancedBaseDownloader):
        def get_content_type_name(self) -> str:
            return "my_content"

        def fetch_content_list(self, course) -> List[Any]:
            return []  # Implement content fetching

        def extract_metadata(self, item: Any) -> Dict[str, Any]:
            return {}  # Implement metadata extraction

        async def download_item(self, item: Any, course_folder: Path,
                               metadata: Dict[str, Any]) -> Optional[Dict[str, Any]]:
            return {}  # Implement item downloading
"""

import asyncio
import json
import os
import time
import traceback
from abc import ABC, abstractmethod
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Tuple
import aiohttp
import aiofiles

from ..config.settings import get_config
from ..utils.logger import get_logger
from ..utils.progress import ProgressTracker


class DownloadError(Exception):
    """Custom exception for download-related errors."""
    pass


class ConfigurationAccessMixin:
    """
    Mixin to provide bulletproof configuration access.

    This mixin provides multiple ways to access configuration values
    with comprehensive fallback mechanisms.
    """

    def safe_config_get(self, key_path: str, default: Any = None, expected_type: type = None) -> Any:
        """
        Safely get configuration value with multiple access methods.

        Args:
            key_path: Configuration key path (e.g., 'download_settings.max_retries')
            default: Default value if not found
            expected_type: Expected type for validation

        Returns:
            Configuration value or default
        """
        if not hasattr(self, 'config'):
            return default

        try:
            # Method 1: Try attribute access (new system)
            keys = key_path.split('.')
            if len(keys) == 2:
                section, key = keys
                try:
                    section_obj = getattr(self.config, section)
                    value = getattr(section_obj, key)
                    if value is not None:
                        if expected_type and not isinstance(value, expected_type):
                            value = expected_type(value)
                        return value
                except (AttributeError, ValueError, TypeError):
                    pass

            # Method 2: Try safe_get method
            try:
                value = self.config.safe_get(key_path, default, expected_type)
                if value != default:
                    return value
            except Exception:
                pass

            # Method 3: Try regular get method
            try:
                value = self.config.get(key_path, default)
                if value is not None and expected_type:
                    value = expected_type(value)
                return value
            except Exception:
                pass

            # Method 4: Return default
            return default

        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.debug(f"Config access failed for {key_path}, using default", exception=e)
            return default


class EnhancedBaseDownloader(ABC, ConfigurationAccessMixin):
    """
    Enhanced Base Downloader with Bulletproof Configuration Integration

    This abstract base class provides a robust foundation for all content
    downloaders with comprehensive error handling, multiple configuration
    access patterns, and intelligent fallback mechanisms.

    The Enhanced Base Downloader is designed to NEVER crash due to configuration
    issues or missing settings. Instead, it provides graceful fallbacks and
    detailed logging for troubleshooting.
    """

    def __init__(self, canvas_client, progress_tracker: ProgressTracker = None):
        """
        Initialize the enhanced base downloader.

        Args:
            canvas_client: Canvas API client instance
            progress_tracker: Optional progress tracker for UI updates
        """
        self.canvas_client = canvas_client
        self.progress_tracker = progress_tracker
        self.config = get_config()
        self.logger = get_logger(__name__)

        # Initialize download statistics
        self.stats = {
            'total_items': 0,
            'downloaded_items': 0,
            'skipped_items': 0,
            'failed_items': 0,
            'total_size_bytes': 0,
            'start_time': None,
            'end_time': None,
            'duration_seconds': 0,
            'errors': [],
            'warnings': []
        }

        # Initialize download configuration with bulletproof access
        self._initialize_download_config()

        # File management
        self.course_folder = None
        self.metadata_file = None
        self.processed_items = set()

        # HTTP session for downloads
        self._session = None
        self._session_timeout = None

        self.logger.info(f"Initialized {self.__class__.__name__}",
                        max_retries=self.max_retries,
                        chunk_size=self.chunk_size,
                        verify_downloads=self.verify_downloads,
                        timeout=self.timeout)

    def _initialize_download_config(self) -> None:
        """Initialize download configuration with bulletproof access and safe defaults."""
        try:
            # Download settings with multiple access methods and safe defaults
            self.max_retries = self.safe_config_get('download_settings.max_retries', 3, int)
            self.retry_delay = self.safe_config_get('download_settings.retry_delay', 1.0, float)
            self.chunk_size = self.safe_config_get('download_settings.chunk_size', 8192, int)
            self.timeout = self.safe_config_get('download_settings.timeout', 30, int)
            self.verify_downloads = self.safe_config_get('download_settings.verify_downloads', True, bool)
            self.skip_existing = self.safe_config_get('download_settings.skip_existing', True, bool)
            self.parallel_downloads = self.safe_config_get('download_settings.parallel_downloads', 4, int)
            self.max_file_size_mb = self.safe_config_get('download_settings.max_file_size_mb', 500, int)

            # File type restrictions
            self.allowed_extensions = self.safe_config_get('download_settings.allowed_extensions', [], list)
            self.blocked_extensions = self.safe_config_get('download_settings.blocked_extensions',
                                                         ['.exe', '.bat', '.cmd', '.scr'], list)

            # Validate settings
            self._validate_download_settings()

            self.logger.debug("Download configuration initialized successfully",
                            max_retries=self.max_retries,
                            chunk_size=self.chunk_size,
                            timeout=self.timeout)

        except Exception as e:
            self.logger.error("Failed to initialize download config, using safe defaults", exception=e)
            self._set_safe_defaults()

    def _set_safe_defaults(self) -> None:
        """Set safe default values for all configuration options."""
        self.max_retries = 3
        self.retry_delay = 1.0
        self.chunk_size = 8192
        self.timeout = 30
        self.verify_downloads = True
        self.skip_existing = True
        self.parallel_downloads = 4
        self.max_file_size_mb = 500
        self.allowed_extensions = []
        self.blocked_extensions = ['.exe', '.bat', '.cmd', '.scr']

        self.logger.warning("Using safe default configuration values")

    def _validate_download_settings(self) -> None:
        """Validate and fix download settings."""
        # Ensure positive values
        if self.max_retries < 0:
            self.max_retries = 3
            self.logger.warning("Fixed negative max_retries value")

        if self.chunk_size <= 0:
            self.chunk_size = 8192
            self.logger.warning("Fixed invalid chunk_size value")

        if self.timeout <= 0:
            self.timeout = 30
            self.logger.warning("Fixed invalid timeout value")

        if self.parallel_downloads <= 0:
            self.parallel_downloads = 1
            self.logger.warning("Fixed invalid parallel_downloads value")
        elif self.parallel_downloads > 20:
            self.parallel_downloads = 20
            self.logger.warning("Limited parallel_downloads to maximum of 20")

        if self.max_file_size_mb <= 0:
            self.max_file_size_mb = 500
            self.logger.warning("Fixed invalid max_file_size_mb value")

        # Ensure lists are actually lists
        if not isinstance(self.allowed_extensions, list):
            self.allowed_extensions = []
            self.logger.warning("Fixed invalid allowed_extensions type")

        if not isinstance(self.blocked_extensions, list):
            self.blocked_extensions = ['.exe', '.bat', '.cmd', '.scr']
            self.logger.warning("Fixed invalid blocked_extensions type")

    @abstractmethod
    def get_content_type_name(self) -> str:
        """
        Get the content type name for this downloader.

        Returns:
            str: The content type identifier (e.g., 'assignments', 'modules')
        """
        pass

    @abstractmethod
    def fetch_content_list(self, course) -> List[Any]:
        """
        Fetch the list of content items from the course.

        Args:
            course: Canvas course object

        Returns:
            List[Any]: List of content items to process
        """
        pass

    @abstractmethod
    def extract_metadata(self, item: Any) -> Dict[str, Any]:
        """
        Extract metadata from a content item.

        Args:
            item: Content item object

        Returns:
            Dict[str, Any]: Metadata dictionary
        """
        pass

    @abstractmethod
    async def download_item(self, item: Any, course_folder: Path,
                           metadata: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Download a specific content item.

        Args:
            item: Canvas content item object
            course_folder: Base folder for the course
            metadata: Pre-extracted item metadata

        Returns:
            Optional[Dict[str, Any]]: Download information or None if skipped
        """
        pass

    def setup_course_folder(self, course_info: Dict[str, Any]) -> Path:
        """
        Set up and create the course folder structure.

        Args:
            course_info: Dictionary containing course information

        Returns:
            Path: The course folder path
        """
        try:
            # Get base download directory with multiple access methods
            downloads_base = None

            # Try different ways to get downloads folder
            try:
                downloads_base = self.config.paths.downloads_folder
            except AttributeError:
                downloads_base = self.safe_config_get('paths.downloads_folder', 'downloads', str)

            downloads_base = Path(downloads_base)

            # Create course folder based on organization preferences
            course_folder = self._build_course_path(downloads_base, course_info)

            # Create the folder structure
            course_folder.mkdir(parents=True, exist_ok=True)

            # Create content type subfolder
            content_folder = course_folder / self.get_content_type_name()
            content_folder.mkdir(exist_ok=True)

            # Set up metadata file path
            self.metadata_file = content_folder / f"{self.get_content_type_name()}_metadata.json"

            # Store for later use
            self.course_folder = content_folder

            self.logger.info(f"Course folder setup complete",
                           course_folder=str(course_folder),
                           content_folder=str(content_folder))

            return content_folder

        except Exception as e:
            self.logger.error(f"Failed to setup course folder", exception=e)
            # Emergency fallback
            fallback_path = Path('downloads') / 'emergency_fallback' / self.get_content_type_name()
            fallback_path.mkdir(parents=True, exist_ok=True)
            self.course_folder = fallback_path
            return fallback_path

    def _build_course_path(self, base_path: Path, course_info: Dict[str, Any]) -> Path:
        """
        Build the course folder path based on configuration.

        Args:
            base_path: Base downloads directory
            course_info: Course information

        Returns:
            Path: Course folder path
        """
        try:
            # Get folder organization preferences
            organize_by_semester = self.safe_config_get('folder_structure.organize_by_semester', True, bool)
            folder_template = self.safe_config_get('folder_structure.folder_name_template',
                                                 '{course_code}-{course_name}', str)

            path_parts = []

            # Add semester organization if enabled
            if organize_by_semester:
                current_year = datetime.now().year
                semester = self._determine_semester(course_info)
                path_parts.extend([str(current_year), semester])

            # Build course folder name
            course_name = self._build_course_folder_name(course_info, folder_template)
            path_parts.append(course_name)

            # Construct full path
            course_path = base_path
            for part in path_parts:
                course_path = course_path / self._sanitize_folder_name(part)

            return course_path

        except Exception as e:
            self.logger.error(f"Failed to build course path", exception=e)
            # Simple fallback
            safe_name = self._sanitize_folder_name(course_info.get('name', 'Unknown_Course'))
            return base_path / safe_name

    def _determine_semester(self, course_info: Dict[str, Any]) -> str:
        """Determine semester from course information."""
        course_name = course_info.get('name', '').lower()

        if any(term in course_name for term in ['fall', 'autumn']):
            return 'Fall'
        elif 'spring' in course_name:
            return 'Spring'
        elif 'summer' in course_name:
            return 'Summer'
        elif 'winter' in course_name:
            return 'Winter'
        else:
            # Determine by current date
            month = datetime.now().month
            if month in [8, 9, 10, 11, 12]:
                return 'Fall'
            elif month in [1, 2, 3, 4, 5]:
                return 'Spring'
            else:
                return 'Summer'

    def _build_course_folder_name(self, course_info: Dict[str, Any], template: str) -> str:
        """Build course folder name from template."""
        try:
            course_code = course_info.get('course_code', 'UNKNOWN')
            course_name = course_info.get('name', 'Unknown Course')

            # Clean up course name (remove code if already present)
            if course_code and course_code in course_name:
                course_name = course_name.replace(course_code, '').strip(' -_')

            folder_name = template.format(
                course_code=course_code,
                course_name=course_name,
                course_id=course_info.get('id', ''),
                full_name=course_info.get('name', '')
            )

            return folder_name

        except Exception as e:
            self.logger.warning(f"Failed to build folder name from template", exception=e)
            # Simple fallback
            return f"{course_info.get('course_code', 'UNKNOWN')}-{course_info.get('name', 'Unknown')}"

    def _sanitize_folder_name(self, name: str) -> str:
        """Sanitize folder name for filesystem compatibility."""
        # Remove invalid characters
        invalid_chars = '<>:"/\\|?*'
        sanitized = name

        for char in invalid_chars:
            sanitized = sanitized.replace(char, '_')

        # Remove leading/trailing dots and spaces
        sanitized = sanitized.strip('. ')

        # Limit length
        if len(sanitized) > 100:
            sanitized = sanitized[:97] + "..."

        # Ensure not empty
        if not sanitized:
            sanitized = "Unnamed"

        return sanitized

    async def download_course_content(self, course, course_info: Dict[str, Any]) -> Dict[str, Any]:
        """
        Download all content for a course.

        Args:
            course: Canvas course object
            course_info: Course information dictionary

        Returns:
            Dict[str, Any]: Download statistics and results
        """
        self.stats['start_time'] = datetime.now()

        try:
            self.logger.info(f"Starting {self.get_content_type_name()} download",
                           course_name=course_info.get('name', 'Unknown'),
                           course_id=str(course.id))

            # Set up course folder
            course_folder = self.setup_course_folder(course_info)

            # Check if content type is enabled
            if not self._is_content_type_enabled():
                self.logger.info(f"{self.get_content_type_name()} download is disabled")
                return self.stats

            # Fetch content items
            items = await self._safe_fetch_content_list(course)

            if not items:
                self.logger.info(f"No {self.get_content_type_name()} found in course")
                return self.stats

            self.stats['total_items'] = len(items)

            # Update progress tracker
            if self.progress_tracker:
                self.progress_tracker.set_total_items(len(items))

            # Process items
            items_metadata = []

            async with self._get_http_session() as session:
                self._session = session

                for index, item in enumerate(items, 1):
                    try:
                        await self._process_single_item(item, course_folder, index, items_metadata)

                    except Exception as e:
                        self.logger.error(f"Failed to process item {index}", exception=e)
                        self.stats['failed_items'] += 1
                        self.stats['errors'].append(f"Item {index}: {str(e)}")

            # Save metadata
            await self._save_metadata(items_metadata)

            # Calculate final statistics
            self._finalize_stats()

            self.logger.info(f"Completed {self.get_content_type_name()} download",
                           **{k: v for k, v in self.stats.items()
                              if k not in ['errors', 'warnings', 'start_time', 'end_time']})

            return self.stats

        except Exception as e:
            self.logger.error(f"Course content download failed", exception=e)
            self.stats['errors'].append(f"Download failed: {str(e)}")
            self._finalize_stats()
            return self.stats

    def _is_content_type_enabled(self) -> bool:
        """Check if this content type is enabled for download."""
        try:
            return self.config.is_content_type_enabled(self.get_content_type_name())
        except Exception:
            # Safe fallback - assume enabled if we can't check
            return True

    async def _safe_fetch_content_list(self, course) -> List[Any]:
        """Safely fetch content list with error handling."""
        try:
            items = self.fetch_content_list(course)
            if items is None:
                return []
            return list(items)

        except Exception as e:
            self.logger.error(f"Failed to fetch {self.get_content_type_name()} list", exception=e)
            self.stats['errors'].append(f"Failed to fetch content list: {str(e)}")
            return []

    async def _process_single_item(self, item: Any, course_folder: Path,
                                  index: int, items_metadata: List[Dict[str, Any]]) -> None:
        """Process a single content item with comprehensive error handling."""
        try:
            # Extract metadata
            metadata = self.extract_metadata(item)
            metadata['index'] = index
            metadata['content_type'] = self.get_content_type_name()

            # Update progress
            if self.progress_tracker:
                item_name = metadata.get('title', f'Item {index}')
                self.progress_tracker.update_current_item(item_name)

            # Download the item
            download_info = await self.download_item(item, course_folder, metadata)

            if download_info:
                metadata.update(download_info)
                self.stats['downloaded_items'] += 1

                # Add to file size tracking
                if 'file_size' in download_info:
                    self.stats['total_size_bytes'] += download_info['file_size']

            else:
                self.stats['skipped_items'] += 1

            items_metadata.append(metadata)

            # Update progress
            if self.progress_tracker:
                self.progress_tracker.increment_progress()

        except Exception as e:
            self.logger.error(f"Failed to process {self.get_content_type_name()} item",
                            item_id=getattr(item, 'id', 'unknown'), exception=e)
            self.stats['failed_items'] += 1
            self.stats['errors'].append(f"Item {index}: {str(e)}")

    async def _get_http_session(self) -> aiohttp.ClientSession:
        """Get HTTP session for downloads."""
        timeout = aiohttp.ClientTimeout(total=self.timeout)
        connector = aiohttp.TCPConnector(limit=self.parallel_downloads)

        return aiohttp.ClientSession(
            timeout=timeout,
            connector=connector,
            headers={'User-Agent': 'Canvas-Downloader/1.0'}
        )

    async def _save_metadata(self, items_metadata: List[Dict[str, Any]]) -> None:
        """Save metadata file with error handling."""
        if not self.metadata_file or not items_metadata:
            return

        try:
            metadata_content = {
                'content_type': self.get_content_type_name(),
                'download_date': datetime.now().isoformat(),
                'total_items': len(items_metadata),
                'items': items_metadata,
                'statistics': self.stats.copy()
            }

            async with aiofiles.open(self.metadata_file, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(metadata_content, indent=2, ensure_ascii=False))

            self.logger.debug(f"Saved metadata file", file_path=str(self.metadata_file))

        except Exception as e:
            self.logger.error(f"Failed to save metadata", exception=e)
            self.stats['warnings'].append(f"Failed to save metadata: {str(e)}")

    def _finalize_stats(self) -> None:
        """Finalize download statistics."""
        self.stats['end_time'] = datetime.now()

        if self.stats['start_time']:
            duration = self.stats['end_time'] - self.stats['start_time']
            self.stats['duration_seconds'] = duration.total_seconds()

        # Calculate success rate
        total_processed = self.stats['downloaded_items'] + self.stats['skipped_items'] + self.stats['failed_items']
        if total_processed > 0:
            self.stats['success_rate'] = (self.stats['downloaded_items'] + self.stats['skipped_items']) / total_processed
        else:
            self.stats['success_rate'] = 1.0

    def is_file_allowed(self, filename: str) -> bool:
        """
        Check if file is allowed based on extension filters.

        Args:
            filename: Name of the file to check

        Returns:
            bool: True if file is allowed
        """
        try:
            file_ext = Path(filename).suffix.lower()

            # Check blocked extensions
            if file_ext in self.blocked_extensions:
                self.logger.debug(f"File blocked by extension", filename=filename, extension=file_ext)
                return False

            # Check allowed extensions (if specified)
            if self.allowed_extensions and file_ext not in self.allowed_extensions:
                self.logger.debug(f"File not in allowed extensions", filename=filename, extension=file_ext)
                return False

            return True

        except Exception as e:
            self.logger.warning(f"Error checking file extension", filename=filename, exception=e)
            # Default to allowed if we can't check
            return True

    def is_file_size_allowed(self, size_bytes: int) -> bool:
        """
        Check if file size is within allowed limits.

        Args:
            size_bytes: File size in bytes

        Returns:
            bool: True if size is allowed
        """
        max_size_bytes = self.max_file_size_mb * 1024 * 1024

        if size_bytes > max_size_bytes:
            self.logger.debug(f"File too large",
                            size_mb=round(size_bytes / (1024 * 1024), 2),
                            max_mb=self.max_file_size_mb)
            return False

        return True

    def get_safe_filename(self, original_name: str) -> str:
        """
        Get a safe filename for the current filesystem.

        Args:
            original_name: Original filename

        Returns:
            str: Safe filename
        """
        # Remove invalid characters
        invalid_chars = '<>:"/\\|?*'
        safe_name = original_name

        for char in invalid_chars:
            safe_name = safe_name.replace(char, '_')

        # Handle reserved names on Windows
        reserved_names = {
            'CON', 'PRN', 'AUX', 'NUL',
            'COM1', 'COM2', 'COM3', 'COM4', 'COM5', 'COM6', 'COM7', 'COM8', 'COM9',
            'LPT1', 'LPT2', 'LPT3', 'LPT4', 'LPT5', 'LPT6', 'LPT7', 'LPT8', 'LPT9'
        }

        name_without_ext = safe_name.rsplit('.', 1)[0] if '.' in safe_name else safe_name
        if name_without_ext.upper() in reserved_names:
            safe_name = f"_{safe_name}"

        # Limit length
        if len(safe_name) > 255:
            name_part = safe_name.rsplit('.', 1)[0] if '.' in safe_name else safe_name
            ext_part = safe_name.rsplit('.', 1)[1] if '.' in safe_name else ''

            max_name_length = 255 - len(ext_part) - 1 if ext_part else 255
            name_part = name_part[:max_name_length]

            safe_name = f"{name_part}.{ext_part}" if ext_part else name_part

        # Ensure not empty
        if not safe_name.strip():
            safe_name = "unnamed_file"

        return safe_name

    async def download_file_with_retry(self, url: str, file_path: Path,
                                     expected_size: int = None) -> bool:
        """
        Download file with retry logic and comprehensive error handling.

        Args:
            url: URL to download from
            file_path: Local file path to save to
            expected_size: Expected file size for validation

        Returns:
            bool: True if download successful
        """
        if not self._session:
            self.logger.error("No HTTP session available for download")
            return False

        for attempt in range(1, self.max_retries + 1):
            try:
                self.logger.debug(f"Download attempt {attempt}", url=url, file_path=str(file_path))

                async with self._session.get(url) as response:
                    response.raise_for_status()

                    # Check content length if expected size provided
                    content_length = response.headers.get('content-length')
                    if content_length and expected_size:
                        if int(content_length) != expected_size:
                            self.logger.warning(f"Size mismatch detected",
                                              expected=expected_size,
                                              actual=int(content_length))

                    # Ensure parent directory exists
                    file_path.parent.mkdir(parents=True, exist_ok=True)

                    # Download file
                    async with aiofiles.open(file_path, 'wb') as f:
                        async for chunk in response.content.iter_chunked(self.chunk_size):
                            await f.write(chunk)

                # Verify file if requested
                if self.verify_downloads and expected_size:
                    actual_size = file_path.stat().st_size
                    if actual_size != expected_size:
                        self.logger.error(f"Downloaded file size mismatch",
                                        expected=expected_size,
                                        actual=actual_size)
                        file_path.unlink(missing_ok=True)
                        continue

                self.logger.debug(f"File downloaded successfully", file_path=str(file_path))
                return True

            except Exception as e:
                self.logger.warning(f"Download attempt {attempt} failed",
                                  url=url, exception=e)

                # Clean up partial file
                if file_path.exists():
                    file_path.unlink(missing_ok=True)

                # Wait before retry (unless last attempt)
                if attempt < self.max_retries:
                    await asyncio.sleep(self.retry_delay)

        self.logger.error(f"All download attempts failed", url=url)
        return False

    def should_skip_existing_file(self, file_path: Path, expected_size: int = None) -> bool:
        """
        Determine if existing file should be skipped.

        Args:
            file_path: Path to check
            expected_size: Expected file size

        Returns:
            bool: True if file should be skipped
        """
        if not self.skip_existing:
            return False

        if not file_path.exists():
            return False

        # If expected size provided, validate it
        if expected_size is not None:
            try:
                actual_size = file_path.stat().st_size
                if actual_size != expected_size:
                    self.logger.debug(f"File size mismatch, re-downloading",
                                    file_path=str(file_path),
                                    expected=expected_size,
                                    actual=actual_size)
                    return False
            except Exception:
                return False

        self.logger.debug(f"Skipping existing file", file_path=str(file_path))
        return True

    def get_download_statistics(self) -> Dict[str, Any]:
        """Get comprehensive download statistics."""
        stats = self.stats.copy()

        # Add calculated fields
        if stats['total_items'] > 0:
            stats['download_rate'] = stats['downloaded_items'] / stats['total_items']
            stats['skip_rate'] = stats['skipped_items'] / stats['total_items']
            stats['failure_rate'] = stats['failed_items'] / stats['total_items']

        # Format file size
        if stats['total_size_bytes'] > 0:
            stats['total_size_mb'] = round(stats['total_size_bytes'] / (1024 * 1024), 2)
            stats['total_size_gb'] = round(stats['total_size_bytes'] / (1024 * 1024 * 1024), 3)

        # Format duration
        if stats['duration_seconds'] > 0:
            duration = timedelta(seconds=stats['duration_seconds'])
            stats['duration_formatted'] = str(duration)

        return stats


# Utility functions
def create_enhanced_downloader(downloader_class, *args, **kwargs):
    """
    Factory function to create enhanced downloader instances.

    Args:
        downloader_class: Downloader class to instantiate
        *args: Positional arguments
        **kwargs: Keyword arguments

    Returns:
        Enhanced downloader instance
    """
    try:
        return downloader_class(*args, **kwargs)
    except Exception as e:
        logger = get_logger(__name__)
        logger.error(f"Failed to create downloader {downloader_class.__name__}", exception=e)
        raise DownloadError(f"Could not create downloader: {e}")